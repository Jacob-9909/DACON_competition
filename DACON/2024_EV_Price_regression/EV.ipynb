{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 1130,
     "status": "ok",
     "timestamp": 1709629469115,
     "user": {
      "displayName": "김주성",
      "userId": "15933598741412346521"
     },
     "user_tz": -540
    },
    "id": "faAF5T4zir2v"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed=42\n",
    "seed_everything(seed) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdUvCXrvjZGJ"
   },
   "source": [
    "#### 데이터 불러오기 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "executionInfo": {
     "elapsed": 4889,
     "status": "ok",
     "timestamp": 1709629474002,
     "user": {
      "displayName": "김주성",
      "userId": "15933598741412346521"
     },
     "user_tz": -540
    },
    "id": "Zjd8vU7BitoE"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('ID',axis=1)\n",
    "test = test.drop('ID',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측값을 각 열의 평균으로 대체\n",
    "# train['배터리용량'] = train.groupby(['제조사', '모델'])['배터리용량'].transform(\n",
    "#     lambda x: x.fillna(x.mean()))\n",
    "# 남은 결측치는 전체 평균값으로 대체\n",
    "train['배터리용량'].fillna(train['배터리용량'].median(), inplace=True)\n",
    "# train['로그_주행거리'] = np.log1p(train['주행거리(km)'])\n",
    "\n",
    "# # 1. 훈련 데이터에 타겟 인코딩 적용\n",
    "# target_encoder = TargetEncoder(cols=['배터리용량'])\n",
    "# train['배터리용량_타겟'] = target_encoder.fit_transform(train['배터리용량'], train['가격(백만원)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측값을 각 열의 평균으로 대체\n",
    "# test['배터리용량'] = test.groupby(['제조사', '모델'])['배터리용량'].transform(\n",
    "#     lambda x: x.fillna(x.mean()))\n",
    "# 남은 결측치는 전체 평균값으로 대체\n",
    "test['배터리용량'].fillna(test['배터리용량'].median(), inplace=True)\n",
    "# test['로그_주행거리'] = np.log1p(test['주행거리(km)'])\n",
    "\n",
    "\n",
    "# 2. 테스트 데이터에도 같은 매핑 값 적용\n",
    "# 테스트 데이터는 따로 로드된다고 가정\n",
    "# test['배터리용량_타겟'] = target_encoder.transform(test['배터리용량'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- --- -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### category 화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 949,
     "status": "ok",
     "timestamp": 1709629478160,
     "user": {
      "displayName": "김주성",
      "userId": "15933598741412346521"
     },
     "user_tz": -540
    },
    "id": "ZD7D49Rii5Zu"
   },
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    '제조사'\n",
    "    ,'모델'\n",
    "    ,'차량상태'\n",
    "    ,'구동방식'\n",
    "    ,'사고이력'\n",
    "]\n",
    "for i in categorical_features:\n",
    "    train[i] = train[i].astype('category')\n",
    "    test[i] = test[i].astype('category')\n",
    "    \n",
    "target= train['가격(백만원)']\n",
    "train = train.drop('가격(백만원)', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1709629478659,
     "user": {
      "displayName": "김주성",
      "userId": "15933598741412346521"
     },
     "user_tz": -540
    },
    "id": "n7EodujAOkz4"
   },
   "outputs": [],
   "source": [
    "train_X, valid_X, train_y, valid_y = train_test_split(train, target, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNqmzG8JABjH"
   },
   "source": [
    "##### lgbm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 500 candidates, totalling 5000 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8999999999999999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8999999999999999\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9999999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9999999999999999\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8999999999999999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8999999999999999\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9999999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9999999999999999\n",
      "[LightGBM] [Info] Total Bins 408\n",
      "[LightGBM] [Info] Number of data points in the train set: 5997, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 62.221487\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "최적 하이퍼파라미터: {'num_leaves': 15, 'n_estimators': 100, 'min_split_gain': 0.0, 'min_data_in_leaf': 7, 'max_depth': 4, 'learning_rate': 0.2, 'feature_fraction': 0.8999999999999999, 'bagging_fraction': 0.9999999999999999}\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8999999999999999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8999999999999999\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9999999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9999999999999999\n",
      "테스트 데이터 RMSE: 1.4335\n"
     ]
    }
   ],
   "source": [
    "# LightGBM 모델 정의\n",
    "lgb_model = lgb.LGBMRegressor(force_row_wise=True, random_state=42)\n",
    "\n",
    "# 랜덤 서치 하이퍼파라미터 공간 정의\n",
    "param_dist = {\n",
    "    'num_leaves': np.arange(5, 31, 5).tolist(),          # 리프 수 감소\n",
    "    'learning_rate': np.arange(0.01, 0.5, 0.01).tolist(),# 학습 속도 줄임\n",
    "    'n_estimators': np.arange(50, 301, 50).tolist(),     # 더 많은 부스팅 라운드\n",
    "    'max_depth': [2, 4, 8, 16],                          # 깊이 제한 완화\n",
    "    'min_data_in_leaf': np.arange(1, 11, 2).tolist(),    # 리프의 최소 데이터 수 감소\n",
    "    'min_split_gain': np.arange(0.0, 0.05, 0.01).tolist(), # 최소 분할 이득\n",
    "    'bagging_fraction': np.arange(0.7, 1.0, 0.1).tolist(), # 데이터 샘플링\n",
    "    'feature_fraction': np.arange(0.7, 1.0, 0.1).tolist() # 피처 샘플링\n",
    "}\n",
    "\n",
    "# 랜덤 서치 객체 생성\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=500,  # 랜덤 샘플링 횟수\n",
    "    scoring='neg_root_mean_squared_error',  # 평가 지표\n",
    "    cv=10,  # 교차 검증 폴드 수\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # 병렬 처리\n",
    ")\n",
    "\n",
    "# 랜덤 서치 실행\n",
    "random_search.fit(train_X, train_y, categorical_feature=categorical_features)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"최적 하이퍼파라미터:\", random_search.best_params_)\n",
    "\n",
    "# 최적 모델로 테스트 데이터 예측\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(valid_X)\n",
    "\n",
    "# RMSE 계산\n",
    "rmse = root_mean_squared_error(valid_y, y_pred)\n",
    "print(f\"테스트 데이터 RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zo6lSuWhjmpw"
   },
   "source": [
    "#### 예측값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "OS9V5mUii9sa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8999999999999999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8999999999999999\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9999999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "pred = best_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "M5nHAD64i_nQ"
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv('sample_submission.csv')\n",
    "submit['가격(백만원)'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "9jhgaVCcjCb-"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "formatted_time = now.strftime(\"%Y%m%d_%H%M\")  \n",
    "file_path = f\"submission_{formatted_time}.csv\"\n",
    "submit.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPtXI13uHfeEbYg576gwwy8",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
